{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pythonç¨‹åºè®¾è®¡ä¸æ•°æ®ç§‘å­¦å¯¼è®ºæœŸä¸­å¤§ä½œä¸šæŠ¥å‘Š\n",
    "#### å¾é– 2200012917 ä¿¡æ¯ç§‘å­¦æŠ€æœ¯å­¦é™¢\n",
    "## ä¸»é¢˜ : åŸºäºè§‚å½±æ•°æ®é›†çš„æ•°æ®åˆ†æä¸æŒ–æ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸€ã€ä¼ ç»Ÿåå¥½å‘ç°\n",
    "- è¡¡é‡åå¥½ç¨‹åº¦çš„æŒ‡æ ‡(ä¸‹ä¸ºæŒ‡æ ‡å‡½æ•°è®¡ç®—ä»£ç )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŒ‡æ ‡ä¸€ : (å¹´é¾„æ®µå¹³å‡æ‰“åˆ†-å…¨å±€å¹³å‡æ‰“åˆ†)*è§‚å½±äººæ•°\n",
    "score['score1'] = score['delta_rating'] * np.log(score['count'])\n",
    "print(f\"{value} \")\n",
    "\n",
    "# æŒ‡æ ‡äºŒ : ç»Ÿè®¡é‡ï¼šğ‘…ğ‘=ğ‘Šğ‘…+(1âˆ’ğ‘Š)ğ‘…0\n",
    "alpha = 0.5\n",
    "score['score2'] = alpha * score['count'] / score['count'].mean()\n",
    "score['score2'] = score['score2'].apply(lambda x: min(x, 1))\n",
    "score['score2'] = score['score2'] * score['rating'] + (1 - score['score2']) * mean_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ä¸åŒå¹´é¾„æ®µç”¨æˆ·çš„å‰10ä¸ªç”µå½±(è¿™é‡Œåªå±•ç¤ºäº†under 18,ä»£ç é‡Œå‡æœ‰è¾“å‡º)\n",
    "\n",
    "<img src = '1.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- åŸºäºç”µå½±é£æ ¼çš„å¯è§†åŒ–\n",
    "  - ç”¨äºå¯è§†åŒ–çš„æ•°æ®å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in genre_list:\n",
    "    for j in unique_values:\n",
    "        data_2 = datas[j]\n",
    "        data_2_genre = data_2[data_2[i] == 1]\n",
    "        mean = data_2_genre.rating.mean()\n",
    "        std = data_2_genre.rating.std()\n",
    "        data_2_genre.rating = (data_2_genre.rating - mean) / std\n",
    "        df_2.loc[i, (j, 'mean')] = mean\n",
    "        df_2.loc[i, (j, 'std')] = std\n",
    "        df_2.loc[i, (j, 'count')] = data_2_genre.shape[0]\n",
    "        df_2.loc[i, (j, 'portion')] = df_2.loc[i, (j, 'count')] / num_movies\n",
    "        genre_rating.append(data_2_genre.rating.to_list())\n",
    "\n",
    "for i in genre_list:\n",
    "    sumterm = 0 \n",
    "    for j in unique_values:\n",
    "        sumterm += df_2.loc[i, (j, 'count')]\n",
    "    for j in unique_values:\n",
    "        df_2.loc[i, (j, 'precentage')] = df_2.loc[i, (j, 'count')] / sumterm\n",
    "\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - ä¸åŒå¹´é¾„ç”¨æˆ·å¯¹ä¸åŒç±»å‹ç”µå½±çš„è¯„åˆ†\n",
    "  - ä¸åŒå¹´é¾„ç”¨æˆ·å¯¹ä¸åŒç±»å‹ç”µå½±çš„è§‚çœ‹æ•°é‡\n",
    "  - ä¸åŒå¹´é¾„ç”¨æˆ·å ä¸åŒç±»å‹ç”µå½±è§‚çœ‹æ•°é‡æ¯”ç‡\n",
    "\n",
    "<img src = '1-2.png' width = 500>\n",
    "\n",
    "<img src = '1-3.png' width = 500>\n",
    "\n",
    "<img src = '1-4.png' width = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## äºŒã€ç”¨æˆ·å¯¹ç”µå½±çš„æ‰“åˆ†é¢„æµ‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.ç‰¹å¾å·¥ç¨‹\n",
    "- Onehotç¼–ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['age_desc'])], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df['occ_desc'])], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df['gender'])], axis=1)\n",
    "df.drop(['timestamp', 'zipcode','genres','title','gender','age_desc','occ_desc'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PCAé™ç»´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.9)  \n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ä½¿ç”¨TF-IDF,å°†ç”µå½±ç®€ä»‹è½¬åŒ–ä¸ºç‰¹å¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=100)  # Choose the top 100 most important features\n",
    "intro_tfidf_features = tfidf_vectorizer.fit_transform(df['intro'])\n",
    "intro_tfidf_df = pd.DataFrame(intro_tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df = pd.concat([df, intro_tfidf_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.æ¨¡å‹è®­ç»ƒ\n",
    "- æ•°æ®é›†æ‹†åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['rating']\n",
    "X = df.drop(['rating','movie_id','user_id'] ,axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- é€‰ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œè®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_pca.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='linear')  # çº¿æ€§æ¿€æ´»å‡½æ•°ç”¨äºå›å½’ä»»åŠ¡\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "history = model.fit(X_train_pca, y_train, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. numpyå®ç°mseå‡½æ•°,å¹¶è¿›è¡Œé¢„æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test_pca)\n",
    "mse = np.mean((y_test.values-y_test_pred.transpose())**2)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å¾—åˆ°çš„mse\n",
    "  - æœ€åå»æ‰äº†PCAé™ç»´\n",
    "\n",
    "<img src='221.png' width = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸‰ã€æµ·æŠ¥æŒ‰å†…å®¹èšç±»\n",
    "#### 1. å›¾åƒç‰¹å¾æå–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æå–é¢œè‰²ç›´æ–¹å›¾å’Œç°åº¦ç›´æ–¹å›¾ç‰¹å¾\n",
    "color_hist = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "color_hist = cv2.normalize(color_hist, color_hist).flatten()  # å½’ä¸€åŒ–å¹¶å±•å¼€æˆä¸€ç»´æ•°ç»„\n",
    "\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray_hist = cv2.calcHist([gray_image], [0], None, [256], [0, 256])\n",
    "gray_hist = cv2.normalize(gray_hist, gray_hist).flatten()  # å½’ä¸€åŒ–å¹¶å±•å¼€æˆä¸€ç»´æ•°ç»„\n",
    "\n",
    "# ä½¿ç”¨Img2Vecæ¨¡å‹æå–ç‰¹å¾å‘é‡\n",
    "image_pil = Image.open(image_path)\n",
    "if image_pil.mode != 'RGB':\n",
    "    image_pil = image_pil.convert('RGB')\n",
    "vector = img2vec_model.get_vec(image_pil)\n",
    "\n",
    "# æ‹¼æ¥ç‰¹å¾å‘é‡\n",
    "# feature_vector = np.concatenate((color_hist, gray_hist, vector))\n",
    "feature_vector = vector #æ˜¾ç„¶ç”¨ç›´æ–¹å›¾æ•ˆæœä¸å¤ªå¥½"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.é™ç»´\n",
    "- pcaé™ç»´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)  \n",
    "pca_result = pca.fit_transform(features)\n",
    "df_pca = df.copy()\n",
    "df_pca = pd.concat([df_pca, pd.DataFrame(pca_result)], axis=1)\n",
    "df_pca = df_pca.drop('features', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å°è¯•äº†t-SNEé™ç»´\n",
    "\n",
    "<img src = 't-SNE_visualization.png' width = 500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)  # é€‰æ‹©è¦é™åˆ°çš„ç»´åº¦ï¼Œè¿™é‡Œé€‰æ‹©2ç»´\n",
    "tsne_result = tsne.fit_transform(features)\n",
    "# å°†é™ç»´ç»“æœæ·»åŠ åˆ°DataFrameä¸­\n",
    "df_tsne = df.copy()\n",
    "df_tsne['tsne_1'] = tsne_result[:, 0]\n",
    "df_tsne['tsne_2'] = tsne_result[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.æ— ç›‘ç£èšç±»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pca.drop(columns=['movie_id']).values\n",
    "kmeans = KMeans(n_clusters=5)  \n",
    "kmeans.fit(X)\n",
    "df['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='3.png' width = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.æœ‰ç›‘ç£èšç±»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- åˆ’åˆ†æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(merged_df['features'].tolist())\n",
    "cluster = np.array(merged_df['cluster'].tolist())\n",
    "X = np.concatenate((features, cluster[:, np.newaxis]), axis=1) \n",
    "y = np.array(merged_df['genre_vector'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å¯¹æ¯”äº†kè¿‘é‚»,éšæœºæ£®æ—çš„æ•ˆæœ,æœ€ç»ˆé€‰æ‹©äº†ä½¿ç”¨ç¥ç»ç½‘ç»œåšåˆ†ç±»,ç»†èŠ‚è§ä»£ç \n",
    "  - å‘ç°ä¸é™ç»´æ¯”é™ç»´æ•ˆæœå¥½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),  # è¾“å…¥å±‚\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu),  # éšè—å±‚\n",
    "    tf.keras.layers.Dropout(0.3),  # Dropoutå±‚ï¼Œä¸¢å¼ƒ30%çš„ç¥ç»å…ƒ\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # éšè—å±‚\n",
    "    tf.keras.layers.Dropout(0.5),  # Dropoutå±‚ï¼Œä¸¢å¼ƒ50%çš„ç¥ç»å…ƒ\n",
    "    tf.keras.layers.Dense(64, activation='relu'),  # éšè—å±‚\n",
    "    tf.keras.layers.Dropout(0.5),  # Dropoutå±‚ï¼Œä¸¢å¼ƒ50%çš„ç¥ç»å…ƒ\n",
    "    tf.keras.layers.Dense(18, activation='sigmoid')  # è¾“å‡ºå±‚ï¼Œå› ä¸ºæ˜¯å¤šæ ‡ç­¾åˆ†ç±»ï¼Œä½¿ç”¨sigmoidæ¿€æ´»å‡½æ•°\n",
    "])\n",
    "\n",
    "# ç¼–è¯‘æ¨¡å‹\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # å¤šæ ‡ç­¾åˆ†ç±»é—®é¢˜ï¼Œä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- æœ€ç»ˆçš„accuracy: \n",
    "\n",
    "<img src='333.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ— ç›‘ç£èšç±»ç»“æœä¿¡æ¯åŠ å…¥åˆ°æ¨¡å‹ä¸­è¡¨ç°ä¸ä½³:\n",
    "- æ— ç›‘ç£èšç±»ç®—æ³•å¯èƒ½å¯¹æ•°æ®ä¸­çš„å™ªå£°æˆ–ä¸ç›¸å…³ä¿¡æ¯äº§ç”Ÿè¿‡åº¦æ•æ„Ÿï¼Œå¯¼è‡´èšç±»ç»“æœä¸ç¨³å®šæˆ–ä¸ä¸€è‡´ã€‚è¿™ç§ä¸ä¸€è‡´æ€§å¯èƒ½ä¼šä½¿å¾—å‘ç›‘ç£å­¦ä¹ æ¨¡å‹ä¼ é€’çš„èšç±»ä¿¡æ¯ä¸å¤Ÿå‡†ç¡®æˆ–æœ‰è¯¯å¯¼æ€§\n",
    "- featureç»´åº¦è¾ƒå¤§,æ•°æ®é›†å°,åœ¨æ­¤æƒ…å½¢ä¸‹æ— ç›‘ç£èšç±»ç»“æœç›¸å¯¹featureå¯¹è®­ç»ƒæ¨¡å‹å½±å“å°,åŒæ—¶å®è·µè¯æ˜èšç±»æœ¬èº«é™ä½accuracy,å› æ­¤æ— æ³•é€šè¿‡å¯¹featureèšç±»æé«˜æ— ç›‘ç£èšç±»ç»“æœä¿¡æ¯å¯¹æ¨¡å‹çš„å½±å“"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
